{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "私てっしー、もう数年前からセンサーのリアルタイムデータの保管先に苦労しておりまして。\n",
    "\n",
    "色々な要件を鑑みると、現状Azure Data Lake Storage Gen2(ADLS Gen2)が非常に調子が良さそうと、Previewの段階から思ってたわけです。\n",
    "ただ、ADLS Gen2にぶっこんだデータを分析する方法などは数多あれど、肝心のデータのぶっこみ方法がわからない●\n",
    "\n",
    "（厳密に言うと、[AzCopy、Dictcp、Azure Data Factoryに関しては書いてある](https://docs.microsoft.com/ja-jp/azure/storage/common/storage-use-azcopy-v10?toc=%2fazure%2fstorage%2fblobs%2ftoc.json ))\n",
    "\n",
    "けどさぁ、センサーデータそのままストリームで書き込みたいじゃん？とか厨二なこと考えて試行錯誤したらえらい面倒だった後失敗したのでその記録。。。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADLS Gen2 Interface List\n",
    "\n",
    "ADLS Gen2にファイルを保存するには以下の方法がある。（と、書かれてる。）\n",
    "\n",
    "| API セット                                 | Data Lake Storage Gen1          | Data Lake Storage Gen2 での使用可否 - 共有キー認証を使用        | Data Lake Storage Gen2 での使用可否 - OAuth 認証を使用 |\n",
    "|--------------------------------------------|---------------------------------|-----------------------------------------------------------------|--------------------------------------------------------|\n",
    "| .NET SDK - 管理                            | リンク                          | サポートされていません                                          | 既に使用可能 - リンク                                  |\n",
    "| .NET SDK - ファイル システム               | リンク                          | まだ使用不可能                                                  | まだ使用不可能                                         |\n",
    "| Java SDK - 管理                            | リンク                          | サポートされていません                                          | 既に使用可能 - リンク                                  |\n",
    "| Java SDK - ファイル システム               | リンク                          | まだ使用不可能                                                  | まだ使用不可能                                         |\n",
    "| Node.js - 管理                             | リンク                          | サポートされていません                                          | 既に使用可能 - リンク                                  |\n",
    "| Node.js - ファイル システム                | リンク                          | まだ使用不可能                                                  | まだ使用不可能                                         |\n",
    "| Python - 管理                              | リンク                          | サポートされていません                                          | 既に使用可能 - リンク                                  |\n",
    "| Python - ファイル システム                 | リンク                          | まだ使用不可能                                                  | まだ使用不可能                                         |\n",
    "| REST API - 管理                            | リンク                          | サポートされていません                                          | 既に使用可能 -                                         |\n",
    "| REST API - ファイル システム               | リンク                          | 既に使用可能                                                    | 既に使用可能 - リンク                                  |\n",
    "\n",
    "（https://docs.microsoft.com/ja-jp/azure/storage/blobs/data-lake-storage-upgrade より転記及び編集）\n",
    "\n",
    "要するに、RESTでしか使えない、と言うわけである●（2019-07-12現在）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADLS Gen2 with REST and Shared Key\n",
    "\n",
    "これ、若干語弊があって、階層型記憶構造（https://docs.microsoft.com/ja-jp/azure/storage/blobs/data-lake-storage-namespace） をONにしてなければ、Azure-Storage SDKのBlob Driverで書けるっぽい。けど、階層型記憶構造使いたいんじゃん？と言うわけでRESTでガリガリ書いた。\n",
    "\n",
    "この時、OAuth2使った場合はRefreshの処理とか面倒なのでShared Keyでやればいいやと思ったのが運の尽き・・・"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-2d37819005c7>, line 13)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-2d37819005c7>\"\u001b[0;36m, line \u001b[0;32m13\u001b[0m\n\u001b[0;31m    storage_account_name = <STORAGE_ACCOUNT_NAME>\u001b[0m\n\u001b[0m                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import datetime\n",
    "import hmac\n",
    "import hashlib\n",
    "import base64\n",
    "import pprint\n",
    "import json\n",
    "import uuid\n",
    "import re\n",
    "import time\n",
    "from dateutil.parser import parse\n",
    "\n",
    "storage_account_name = <STORAGE_ACCOUNT_NAME>\n",
    "storage_account_key = <STORAGE_ACCUNT_KEY>\n",
    "api_version = '2018-11-09'\n",
    "request_id = str(uuid.uuid1())\n",
    "request_time = datetime.datetime.utcnow().strftime('%a, %d %b %Y %H:%M:%S GMT')\n",
    "\n",
    "#the file path on adls gen2\n",
    "FILE_SYSTEM_NAME='<FILE_PATH>\\nresource:file'\n",
    "\n",
    "data = \"<TEST></TEST>\"\n",
    "content_len = str(len(data))\n",
    "\n",
    "string_params = {\n",
    "    'verb': 'PUT',\n",
    "    'Content-Encoding': '',\n",
    "    'Content-Language': '',\n",
    "    'Content-Length': content_len,\n",
    "    'Content-MD5': '',\n",
    "    'Content-Type': '', #application/octet-stream',\n",
    "    'Date': '',\n",
    "    'If-Modified-Since': '',\n",
    "    'If-Match': '',\n",
    "    'If-None-Match': '',\n",
    "    'If-Unmodified-Since': '',\n",
    "    'Range': '',\n",
    "    'CanonicalizedHeaders': f\"x-ms-date:{request_time}\\nx-ms-version:{api_version}\\nx-ms-client-request-id:{request_id}\",\n",
    "    'CanonicalizedResource': f\"/{storage_account_name}/{FILE_SYSTEM_NAME}\"\n",
    "    }\n",
    "\n",
    "string_to_sign = (string_params['verb'] + '\\n'\n",
    "                  + string_params['Content-Encoding'] + '\\n'\n",
    "                  + string_params['Content-Language'] + '\\n'\n",
    "                  + string_params['Content-Length'] + '\\n'\n",
    "                  + string_params['Content-MD5'] + '\\n'\n",
    "                  + string_params['Content-Type'] + '\\n'\n",
    "                  + string_params['Date'] + '\\n'\n",
    "                  + string_params['If-Modified-Since'] + '\\n'\n",
    "                  + string_params['If-Match'] + '\\n'\n",
    "                  + string_params['If-None-Match'] + '\\n'\n",
    "                  + string_params['If-Unmodified-Since'] + '\\n'\n",
    "                  + string_params['Range'] + '\\n'\n",
    "                  + string_params['CanonicalizedHeaders'] + '\\n'\n",
    "                  + string_params['CanonicalizedResource'])\n",
    "\n",
    "pprint.pprint(string_to_sign)\n",
    "\n",
    "signed_string = base64.b64encode(\n",
    "    hmac.new(\n",
    "        base64.b64decode(storage_account_key), \n",
    "        msg=string_to_sign.encode('utf-8'), \n",
    "        digestmod=hashlib.sha256).digest()).decode()\n",
    "\n",
    "params = {\n",
    "    'resource': 'file'\n",
    "}\n",
    "\n",
    "headers = {\n",
    "    'x-ms-date' : request_time,\n",
    "    'x-ms-version' : api_version,\n",
    "    'x-ms-client-request-id': request_id,\n",
    "    # 'Content-Type': 'application/octet-stream',\n",
    "    # 'Content-Length': content_len,\n",
    "    'Authorization' : f'SharedKey {storage_account_name}:{signed_string}'\n",
    "}\n",
    "\n",
    "pprint.pprint(string_params)\n",
    "print(headers)\n",
    "url = ('https://' + storage_account_name + '.dfs.core.windows.net/'+'<FILE_PATH>')\n",
    "r = requests.put(url, headers=headers, params=params, data=data)\n",
    "\n",
    "#print out the file content\n",
    "print(r.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SharedKey Authの何が面倒ってこのAuthorization HeaderにくっつけるSigned Stringの生成。ドキュメント見ながらしこしこ書いたんだが、どーにもうまくいかない・・・。\n",
    "というのも、どうも　Content-Lengthに空文字以外を指定するとAuthが通らない、すなわちBodyが入ったRequestができない●（GETでファイルのリスト取るとかはできた）\n",
    "\n",
    "詰んだ・・・orz（これ理解するのに丸一日かかった・・・）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADLS Gen2 with AzCopy\n",
    "\n",
    "んが、どうも色々調べてみたらAzCopyでできるらしい、そしていつの間にかAzCopyがLinux, macOSでも動くようになったと。\n",
    "（AzCopyって文字列見ただけで撥ねてた、Windowsでしか動かないと思ってたから・・）\n",
    "\n",
    "と言うわけで、AzCopyでADLS Gen2にファイルをコピーするシェルスクリプトを書いてみた。\n",
    "\n",
    "\n",
    "```bash\n",
    "storageAccount=<STORAGE_ACCOUNT_NAME>\n",
    "tenantID=<TENANT_ID>\n",
    "applicationID=<Application_ID>\n",
    "clientSecret=<CLIENT_SECRET>\n",
    "filePath=<FILE_PATH>\n",
    "\n",
    "export AZCOPY_SPA_CLIENT_SECRET=$clientSecret\n",
    "./azcopy login --service-principal --application-id $applicationID --tenant-id $tenantID\n",
    "./azcopy cp \"./targetFile.json\" \"https://$storageAccount.dfs.core.windows.net/$filePath\"\n",
    "```\n",
    "\n",
    "前提ですが、サービスプリンシパル作ってClientSecret生成してくださいな。やり方は以下のページにまとまってます。\n",
    "\n",
    "- https://docs.microsoft.com/ja-jp/azure/storage/common/storage-use-azcopy-v10\n",
    "- https://docs.microsoft.com/ja-jp/azure/storage/blobs/data-lake-storage-use-databricks-spark\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AzCopy on Docker\n",
    "\n",
    "さてさて、これで終わらないのがキモ。これ、Dockerで動かそうとすると動かないのです。。。\n",
    "理由はKeyutils使うため。何も考えずにDockerImageにすると、azcopy loginが失敗します。\n",
    "\n",
    "なので、Dockerのセキュリティーポリシーをオーバーライドしないといかんのです。\n",
    "以下が作ったDocker FIle\n",
    "\n",
    "```\n",
    "FROM alpine:3.9.4\n",
    "RUN apk --no-cache add curl jq libc6-compat\n",
    "WORKDIR /root\n",
    "RUN curl -L https://aka.ms/downloadazcopy-v10-linux | tar zx && mv ./azcopy_linux*/azcopy . && chown root:root ./azcopy && rm -rf ./azcopy_linux*\n",
    "ADD azcopy.sh /root\n",
    "ENTRYPOINT [\"/bin/sh\", \"./azcopy.sh\"]\n",
    "```\n",
    "\n",
    "azcopy.sh は、先に書いたシェルスクリプトです。これをビルドして実行するには以下のコマンド。\n",
    "\n",
    "```\n",
    "docker build -t azcopy_test:0.1.0 .\n",
    "docker run -it --rm --security-opt seccomp=unconfined azcopy_test:0.1.0\n",
    "```\n",
    "\n",
    "`--security-opt seccomp=unconfined`がキモ。これを指定するとseccompがunconfinedに設定されてkeyutilsが使えるようになります。ただし、セキュリティーリスクは上がるのでご利用は計画的に。。。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AzCopy on Kubernetes\n",
    "\n",
    "さらに、Docker Imageできたんだからk8sで動かしたくなるわけですよ。ここでもseccompの設定を行う必要あり（ただし、どうも現状だとk8sのdockerはseccompがunconfinedみたいな記述もあり、もしかしたら不要かも。ただし今後効いてくる可能性高し）\n",
    "\n",
    "```kml\n",
    "apiVersion: batch/v1beta1\n",
    "kind: CronJob\n",
    "metadata:\n",
    "  name: azcopy_test\n",
    "  labels:\n",
    "    kind: CronJob\n",
    "  annotations:\n",
    "    # https://kubernetes.io/docs/concepts/policy/pod-security-policy/\n",
    "    seccomp.security.alpha.kubernetes.io/pod: unconfined\n",
    "spec:\n",
    "  schedule: \"* * * * *\"\n",
    "  jobTemplate:\n",
    "    spec:\n",
    "      template:\n",
    "        spec:\n",
    "          containers:\n",
    "            - name: azcopy_test\n",
    "              image: azcopy_test:0.1.0\n",
    "          restartPolicy: Never\n",
    "```\n",
    "\n",
    "こんな風に、annotationとしてpodのseccompをunconfinedにすれば動きます。めでたしめでたし。\n",
    "\n",
    "*注意* 元あったソースからコアの部分抜き出してコードを書いてるので間違ってたらごめんなさい●"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "nikola": {
   "category": "",
   "date": "2019-07-12 10:10:41+09:00",
   "description": "",
   "link": "",
   "slug": "add-file-azure-data-lake-storage-gen2",
   "tags": "",
   "title": "Azure Data Lake Storage Gen2にデータを保存する",
   "type": "text"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
